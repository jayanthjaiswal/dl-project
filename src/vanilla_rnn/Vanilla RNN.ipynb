{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "EEG_channels = 22 #from project guidelines\n",
    "test_count = 50 #from project guideline, 238 for train-validation and 50 for test\n",
    "validation_count = 38 # 38 points in validation set and remaining 200 points in test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from includes import *\n",
    "\n",
    "#################### \"includes\" imports:\n",
    "#\n",
    "#   from read_data import *\n",
    "#   \n",
    "#   import torch\n",
    "#   from torch.autograd import Variable\n",
    "#   import torch.nn as nn\n",
    "#   import torch.optim as optim\n",
    "#\n",
    "#   dtype = torch.cuda.FloatTensor # torch.FloatTensor\n",
    "#\n",
    "#   all_files = [h5py.File(m, 'r') for m in mat_names]\n",
    "#   all_ims = [f['image'] for f in all_files]\n",
    "#   all_types = [f['type'] for f in all_files]\n",
    "#\n",
    "####################\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(288, 25, 1000)\n"
     ]
    }
   ],
   "source": [
    "image_mat = all_ims[0]\n",
    "image_shape = image_mat.shape # 288 (48x6) trials across 25 electrodes for 1000 time points (250Hz*4s)\n",
    "print image_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./project_datasets/A01T_slice.mat', './project_datasets/A02T_slice.mat', './project_datasets/A03T_slice.mat', './project_datasets/A04T_slice.mat', './project_datasets/A05T_slice.mat', './project_datasets/A06T_slice.mat', './project_datasets/A07T_slice.mat', './project_datasets/A08T_slice.mat', './project_datasets/A09T_slice.mat']\n"
     ]
    }
   ],
   "source": [
    "print(mat_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting seed\n",
    "np.random.seed(seed=1337)\n",
    "test_picked = np.random.choice(image_shape[0], test_count, replace=False)\n",
    "train_val_picked = np.setdiff1d(np.arange(image_shape[0]), test_picked)\n",
    "val_picked = train_val_picked[:validation_count]\n",
    "train_picked = train_val_picked[validation_count:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_mat = all_types[0]\n",
    "type_shape = type_mat.shape\n",
    "type_set = list(set(type_mat[0,:]))\n",
    "\n",
    "# all the 0's occur after 288, and are meaningless I think\n",
    "# so the image_mat, which has shape (288, 25, 1000) should correspond\n",
    "# to the first 288 entries of type_mat, so\n",
    "# for a single subject, training data should be image_mat, with 288 samples, each sample has shape (25, 1000)\n",
    "# and our target label matrix should be type_mat[:288] (or 287?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainval_data_X = []\n",
    "training_data_X = []\n",
    "validation_data_X = []\n",
    "test_data_X = []\n",
    "\n",
    "trainval_data_Y = []\n",
    "training_data_Y = []\n",
    "validation_data_Y = []\n",
    "test_data_Y = []\n",
    "\n",
    "for i in range(len(mat_names)):\n",
    "    matfile = h5py.File(mat_names[i], 'r')\n",
    "    \n",
    "    trainval_data_X.append(matfile['image'][sorted(train_val_picked),:EEG_channels,:]) #(238, 22, 1000) x 9\n",
    "    training_data_X.append(matfile['image'][sorted(train_picked),:EEG_channels,:]) #(200, 22, 1000) x 9\n",
    "    validation_data_X.append(matfile['image'][sorted(val_picked),:EEG_channels,:]) #(38, 22, 1000) x 9\n",
    "    test_data_X.append(matfile['image'][sorted(test_picked),:EEG_channels,:]) #(50, 22, 1000) x 9\n",
    "    \n",
    "    trainval_data_Y.append(matfile['type'][0,sorted(train_val_picked)] - type_set[1]) #(238, ) x 9\n",
    "    training_data_Y.append(matfile['type'][0,sorted(train_picked)] - type_set[1]) #(200, ) x 9\n",
    "    validation_data_Y.append(matfile['type'][0,sorted(val_picked)] - type_set[1]) #(38, ) x 9\n",
    "    test_data_Y.append(matfile['type'][0,sorted(test_picked)] - type_set[1]) #(50, ) x 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(mat_names)):\n",
    "    assert(set(training_data_Y[i]) == set(validation_data_Y[i])) #check whether we have data for all labels \n",
    "    assert(set(training_data_Y[i]) == set(test_data_Y[i])) #check whether we have data for all labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before nans: (2142, 22, 1000)\n",
      "before nans: (2115, 22, 1000)\n",
      "before nans: (1800, 22, 1000)\n",
      "before nans: (1775, 22, 1000)\n",
      "before nans: (342, 22, 1000)\n",
      "before nans: (340, 22, 1000)\n",
      "before nans: (450, 22, 1000)\n",
      "before nans: (443, 22, 1000)\n"
     ]
    }
   ],
   "source": [
    "from functools import reduce\n",
    "\n",
    "rnn_trainval_data_X = np.concatenate(trainval_data_X, axis=0) #(2142, 22, 1000)\n",
    "rnn_training_data_X = np.concatenate(training_data_X, axis=0) #(1800, 22, 1000)\n",
    "rnn_validation_data_X = np.concatenate(validation_data_X, axis=0) #(342, 22, 1000)\n",
    "rnn_test_data_X = np.concatenate(test_data_X, axis=0) #(450, 22, 1000)\n",
    "\n",
    "rnn_trainval_data_Y = np.concatenate(trainval_data_Y, axis=0) #(2142, )\n",
    "rnn_training_data_Y = np.concatenate(training_data_Y, axis=0) #(1800, )\n",
    "rnn_validation_data_Y = np.concatenate(validation_data_Y, axis=0) #(342, )\n",
    "rnn_test_data_Y = np.concatenate(test_data_Y, axis=0) #(450,)\n",
    "\n",
    "def remove_nan_rows_A(A, b, debug=True):\n",
    "    if (debug):\n",
    "        print('before nans: {}'.format(str(A.shape)))\n",
    "    if (np.isnan(A).any() or np.isnan(b).any()):\n",
    "        mask = ~np.isnan(np.sum(A,axis=(1,2))) & ~np.isnan(b[:])\n",
    "        A = A[mask, :, :]\n",
    "        b = b[mask]\n",
    "    \n",
    "    if (debug):\n",
    "        print('before nans: {}'.format(str(A.shape)))\n",
    "    assert A.shape[0] == b.shape[0]\n",
    "    return A, b\n",
    "\n",
    "rnn_trainval_data_X, rnn_trainval_data_Y = remove_nan_rows_A(rnn_trainval_data_X,\n",
    "                                                             rnn_trainval_data_Y)\n",
    "rnn_training_data_X, rnn_training_data_Y = remove_nan_rows_A(rnn_training_data_X, \n",
    "                                                             rnn_training_data_Y)\n",
    "rnn_validation_data_X, rnn_validation_data_Y = remove_nan_rows_A(rnn_validation_data_X,\n",
    "                                         rnn_validation_data_Y)\n",
    "rnn_test_data_X, rnn_test_data_Y = remove_nan_rows_A(rnn_test_data_X,\n",
    "                                   rnn_test_data_Y)\n",
    "\n",
    "\n",
    "# repeating the Y labels for the rnn\n",
    "N_trainval, E, T = rnn_trainval_data_X.shape\n",
    "N_training, _, _ = rnn_trainval_data_X.shape\n",
    "N_validation, _, _ = rnn_test_data_X.shape\n",
    "N_test, _, _ = rnn_test_data_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200,)\n"
     ]
    }
   ],
   "source": [
    "print(training_data_Y[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 22, 1000)\n"
     ]
    }
   ],
   "source": [
    "training_data_shape = training_data_X[0].shape\n",
    "print(training_data_shape) #(200, 22, 1000) while test data shape is (50, 22, 1000) and validation data is (38, 22,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2115, 22, 1000)\n",
      "(2115,)\n"
     ]
    }
   ],
   "source": [
    "print rnn_trainval_data_X.shape\n",
    "print rnn_trainval_data_Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pack_padded_sequence as ppseq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1775, 22, 1000])\n",
      "torch.Size([1775])\n"
     ]
    }
   ],
   "source": [
    "tensor_x_train = torch.Tensor(rnn_training_data_X)\n",
    "tensor_y_train = torch.LongTensor(rnn_training_data_Y)\n",
    "\n",
    "print tensor_x_train.shape\n",
    "print tensor_y_train.shape\n",
    "\n",
    "tensor_x_val = torch.Tensor(rnn_validation_data_X)\n",
    "tensor_y_val = torch.LongTensor(rnn_validation_data_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper Parameters\n",
    "num_epochs = 20\n",
    "batch_size = 100\n",
    "learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torch.utils.data.TensorDataset(tensor_x_train,tensor_y_train)\n",
    "val_dataset = torch.utils.data.TensorDataset(tensor_x_val,tensor_y_val)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_dataset,\n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('', VanillaRNN(\n",
      "  (layer1): Sequential(\n",
      "    (0): Conv1d(22, 32, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (initial_layer): Sequential(\n",
      "    (initial_lin_0): Linear(in_features=32, out_features=100, bias=True)\n",
      "    (initial_relu_0): ReLU()\n",
      "  )\n",
      "  (rnn_layer): RNN(100, 100, bias=False)\n",
      "  (output_layer): Sequential(\n",
      "    (output): Linear(in_features=100, out_features=4, bias=True)\n",
      "  )\n",
      ")), ('layer1', Sequential(\n",
      "  (0): Conv1d(22, 32, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "  (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU()\n",
      "  (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ")), ('layer1.0', Conv1d(22, 32, kernel_size=(5,), stride=(1,), padding=(2,))), ('layer1.1', BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)), ('layer1.2', ReLU()), ('layer1.3', MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)), ('initial_layer', Sequential(\n",
      "  (initial_lin_0): Linear(in_features=32, out_features=100, bias=True)\n",
      "  (initial_relu_0): ReLU()\n",
      ")), ('initial_layer.initial_lin_0', Linear(in_features=32, out_features=100, bias=True)), ('initial_layer.initial_relu_0', ReLU()), ('rnn_layer', RNN(100, 100, bias=False)), ('output_layer', Sequential(\n",
      "  (output): Linear(in_features=100, out_features=4, bias=True)\n",
      ")), ('output_layer.output', Linear(in_features=100, out_features=4, bias=True))]\n",
      "torch.Size([32, 22, 5])\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "torch.Size([100, 32])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 100])\n",
      "torch.Size([100, 100])\n",
      "torch.Size([4, 100])\n",
      "torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "from VanillaRNN import VanillaRNN\n",
    "NUM_CLASSES = 4\n",
    "net = VanillaRNN(\n",
    "                conv_layers = True,\n",
    "                initial_hidden_layer_sizes = [100],#[100],\n",
    "                recurrent_hidden_size = 100,\n",
    "                #recurrent_use_bias = True,\n",
    "                final_hidden_layer_sizes = [],#[100, 10],\n",
    "                num_classes=NUM_CLASSES)\n",
    "\n",
    "FCC_SANITY = False\n",
    "\n",
    "#from FC import FC\n",
    "#net = FC()\n",
    "#FCC_SANITY = True\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "#optimizer = torch.optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9)\n",
    "\n",
    "print(list(net.named_modules()))\n",
    "\n",
    "for s in net.parameters():\n",
    "    print('{}'.format(s.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outshape1 torch.Size([1775, 32, 500])\n",
      "outshape2 torch.Size([500, 1775, 32])\n",
      "outshape torch.Size([500, 1775, 4])\n",
      "torch.Size([1775, 4])\n",
      "outshape1 torch.Size([1775, 32, 500])\n",
      "outshape2 torch.Size([500, 1775, 32])\n",
      "outshape torch.Size([500, 1775, 4])\n",
      "torch.Size([1775, 4])\n"
     ]
    }
   ],
   "source": [
    "net.train(True)\n",
    "\n",
    "if (FCC_SANITY):\n",
    "    out = net.forward(tensor_x_train)\n",
    "else:\n",
    "    out, hidden = net.forward(tensor_x_train)\n",
    "print(out.shape)\n",
    "net.train(False)\n",
    "\n",
    "if (FCC_SANITY):\n",
    "    out = net.forward(tensor_x_train)\n",
    "else:    \n",
    "    out, hidden = net.forward(tensor_x_train)\n",
    "    \n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial label shape: torch.Size([100])\n",
      "iteration label set [0 1 2 3]\n",
      "outshape1 torch.Size([100, 32, 500])\n",
      "outshape2 torch.Size([500, 100, 32])\n",
      "outshape torch.Size([500, 100, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:49: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Iter [1/17] Loss: 1.3918\n",
      "initial label shape: torch.Size([100])\n",
      "iteration label set [0 1 2 3]\n",
      "outshape1 torch.Size([100, 32, 500])\n",
      "outshape2 torch.Size([500, 100, 32])\n",
      "outshape torch.Size([500, 100, 4])\n",
      "Epoch [1/20], Iter [2/17] Loss: 1.3956\n",
      "initial label shape: torch.Size([100])\n",
      "iteration label set [0 1 2 3]\n",
      "outshape1 torch.Size([100, 32, 500])\n",
      "outshape2 torch.Size([500, 100, 32])\n",
      "outshape torch.Size([500, 100, 4])\n",
      "Epoch [1/20], Iter [3/17] Loss: 1.3761\n",
      "initial label shape: torch.Size([100])\n",
      "iteration label set [0 1 2 3]\n",
      "outshape1 torch.Size([100, 32, 500])\n",
      "outshape2 torch.Size([500, 100, 32])\n",
      "outshape torch.Size([500, 100, 4])\n",
      "Epoch [1/20], Iter [4/17] Loss: 1.4015\n",
      "initial label shape: torch.Size([100])\n",
      "iteration label set [0 1 2 3]\n",
      "outshape1 torch.Size([100, 32, 500])\n",
      "outshape2 torch.Size([500, 100, 32])\n",
      "outshape torch.Size([500, 100, 4])\n",
      "Epoch [1/20], Iter [5/17] Loss: 1.3865\n",
      "initial label shape: torch.Size([100])\n",
      "iteration label set [0 1 2 3]\n",
      "outshape1 torch.Size([100, 32, 500])\n",
      "outshape2 torch.Size([500, 100, 32])\n",
      "outshape torch.Size([500, 100, 4])\n",
      "Epoch [1/20], Iter [6/17] Loss: 1.3803\n",
      "initial label shape: torch.Size([100])\n",
      "iteration label set [0 1 2 3]\n",
      "outshape1 torch.Size([100, 32, 500])\n",
      "outshape2 torch.Size([500, 100, 32])\n",
      "outshape torch.Size([500, 100, 4])\n",
      "Epoch [1/20], Iter [7/17] Loss: 1.3848\n",
      "initial label shape: torch.Size([100])\n",
      "iteration label set [0 1 2 3]\n",
      "outshape1 torch.Size([100, 32, 500])\n",
      "outshape2 torch.Size([500, 100, 32])\n",
      "outshape torch.Size([500, 100, 4])\n",
      "Epoch [1/20], Iter [8/17] Loss: 1.4022\n",
      "initial label shape: torch.Size([100])\n",
      "iteration label set [0 1 2 3]\n",
      "outshape1 torch.Size([100, 32, 500])\n",
      "outshape2 torch.Size([500, 100, 32])\n",
      "outshape torch.Size([500, 100, 4])\n",
      "Epoch [1/20], Iter [9/17] Loss: 1.4064\n",
      "initial label shape: torch.Size([100])\n",
      "iteration label set [0 1 2 3]\n",
      "outshape1 torch.Size([100, 32, 500])\n",
      "outshape2 torch.Size([500, 100, 32])\n",
      "outshape torch.Size([500, 100, 4])\n",
      "Epoch [1/20], Iter [10/17] Loss: 1.3915\n",
      "initial label shape: torch.Size([100])\n",
      "iteration label set [0 1 2 3]\n",
      "outshape1 torch.Size([100, 32, 500])\n",
      "outshape2 torch.Size([500, 100, 32])\n",
      "outshape torch.Size([500, 100, 4])\n",
      "Epoch [1/20], Iter [11/17] Loss: 1.3927\n",
      "initial label shape: torch.Size([100])\n",
      "iteration label set [0 1 2 3]\n",
      "outshape1 torch.Size([100, 32, 500])\n",
      "outshape2 torch.Size([500, 100, 32])\n",
      "outshape torch.Size([500, 100, 4])\n",
      "Epoch [1/20], Iter [12/17] Loss: 1.3985\n",
      "initial label shape: torch.Size([100])\n",
      "iteration label set [0 1 2 3]\n",
      "outshape1 torch.Size([100, 32, 500])\n",
      "outshape2 torch.Size([500, 100, 32])\n",
      "outshape torch.Size([500, 100, 4])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-105-5b7281e0df64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mloss_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/autograd/variable.pyc\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    118\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m \u001b[0;34m`\u001b[0m\u001b[0;34m`\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m`\u001b[0m\u001b[0;34m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \"\"\"\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/autograd/__init__.pyc\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(variables, grad_variables, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m---> 81\u001b[0;31m         variables, grad_variables, retain_graph, create_graph)\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1111)\n",
    "\n",
    "train_acc = []\n",
    "val_acc = []\n",
    "loss_history = []\n",
    "          \n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    ######################## TRAINING\n",
    "        \n",
    "    net.train(True)\n",
    "    \n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        \n",
    "        #     for i in range(cnn_training_data_X.shape[0]):\n",
    "        images = Variable(images, requires_grad=True) #unsqueeze used to make a 4d tensor because \n",
    "        #     print images.shape\n",
    "        \n",
    "        print('initial label shape: {}'.format(labels.shape))\n",
    "        if (False): #not FCC_SANITY):\n",
    "            labels = labels.repeat(T, 1)\n",
    "            print('repeated label shape {}'.format((labels.shape)))\n",
    "            labels =  labels.view(-1)\n",
    "            \n",
    "        #print(labels)\n",
    "        labels = Variable(labels)\n",
    "        \n",
    "        #print('iteration label mean {}'.format(torch.mean(predicted.float())))\n",
    "\n",
    "        print('iteration label set {}'.format(np.unique(labels.data)))\n",
    "        \n",
    "        # Forward + Backward + Optimize\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        if (FCC_SANITY):\n",
    "            outputs = net(images)\n",
    "        else:    \n",
    "            outputs, hidden = net(images)\n",
    "        \n",
    "        #reshaped_outputs = outputs.view(-1, NUM_CLASSES)\n",
    "        #reshaped_labels = labels.view(-1)\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        loss_history.append(loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print ('Epoch [%d/%d], Iter [%d/%d] Loss: %.4f' \n",
    "               %(epoch+1, num_epochs, i+1, rnn_training_data_X.shape[0]*1.0/batch_size, loss.data[0]))\n",
    "    \n",
    "    ######################## PER EPOCH EVALUATION\n",
    "    net.train(False)\n",
    "    \n",
    "    images = Variable(torch.Tensor(rnn_training_data_X))\n",
    "    test_labels = torch.LongTensor(rnn_training_data_Y)\n",
    "    \n",
    "    if (FCC_SANITY):\n",
    "        outputs = net(images)\n",
    "    else:\n",
    "        outputs, hidden = net(images)\n",
    "    \n",
    "    print(outputs.shape)\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += test_labels.size(0)\n",
    "    correct += (predicted == test_labels).double().sum()\n",
    "    print('Train Accuracy: %d %%' % (100 * correct / total))\n",
    "    train_acc.append((100 * correct / total))\n",
    "\n",
    "    net.eval()  # Change model to 'eval' mode (BN uses moving mean/var).\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    images = Variable(torch.Tensor(rnn_validation_data_X))\n",
    "    test_labels = torch.LongTensor(rnn_validation_data_Y)\n",
    "    \n",
    "    if (FCC_SANITY):\n",
    "        outputs = net(images)\n",
    "    else:\n",
    "        outputs, hidden = net(images)\n",
    "    \n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    \n",
    "    print('predicted set {}'.format(np.unique(predicted.data)))\n",
    "    print('label set {}'.format(np.unique(test_labels.data)))\n",
    "    \n",
    "    total += test_labels.size(0)\n",
    "    correct += (predicted == test_labels).double().sum()\n",
    "    print('validation Accuracy: %d %%' % (100.0 * correct / total))\n",
    "    val_acc.append((100 * correct / total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
