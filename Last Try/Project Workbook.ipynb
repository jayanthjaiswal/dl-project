{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../project_datasets/A07T_slice.mat', '../project_datasets/A02T_slice.mat', '../project_datasets/A05T_slice.mat', '../project_datasets/A08T_slice.mat', '../project_datasets/A03T_slice.mat', '../project_datasets/A06T_slice.mat', '../project_datasets/A01T_slice.mat', '../project_datasets/A04T_slice.mat', '../project_datasets/A09T_slice.mat']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import h5py\n",
    "%matplotlib inline\n",
    "\n",
    "mat_names = glob.glob('../project_datasets/*.mat')\n",
    "# each test subject got a different file - 9 test subjects\n",
    "print(mat_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'image', u'type']\n",
      "(288, 25, 1000)\n"
     ]
    }
   ],
   "source": [
    "matfile = h5py.File(mat_names[0], 'r')\n",
    "print(matfile.keys()) #image and type\n",
    "image_mat = matfile['image']\n",
    "image_shape = image_mat.shape # 288 (48x6) trials across 25 electrodes for 1000 time points (250Hz*4s)\n",
    "print(image_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1000)\n",
      "0\n",
      "288\n",
      "[0.0, 769.0, 770.0, 771.0, 772.0]\n"
     ]
    }
   ],
   "source": [
    "type_mat = matfile['type']\n",
    "type_shape = type_mat.shape\n",
    "print(type_shape)\n",
    "# plt.plot(type_mat[0,:288]) # gets the significant values of types\n",
    "# all the 0's occur after 288, and are meaningless I think\n",
    "# so the image_mat, which has shape (288, 25, 1000) should correspond\n",
    "# to the first 288 entries of type_mat, so\n",
    "# for a single subject, training data should be image_mat, with 288 samples, each sample has shape (25, 1000)\n",
    "# and our target label matrix should be type_mat[:288] (or 287?)\n",
    "nans = np.sum(np.isnan(image_mat[:,:]))\n",
    "print(nans) #No NaN in the data\n",
    "print(len(image_mat[0:,:]))\n",
    "count = 0\n",
    "# for i in range(len(image_mat[0:,:])):\n",
    "#  if np.sum(np.isnan(image_mat[i:,:])):\n",
    "#         pass\n",
    "type_set = list(set(type_mat[0,:]))\n",
    "print(type_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "EEG_channels = 22 #from project guidelines\n",
    "test_count = 50 #from project guideline, 238 for train-validation and 50 for test\n",
    "validation_count = 38 # 38 points in validation set and remaining 200 points in test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting seed\n",
    "np.random.seed(seed=101)\n",
    "test_picked = np.random.choice(image_shape[0], test_count, replace=False)\n",
    "train_val_picked = np.setdiff1d(np.arange(image_shape[0]), test_picked)\n",
    "val_picked = train_val_picked[:validation_count]\n",
    "train_picked = train_val_picked[validation_count:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainval_data_X = []\n",
    "training_data_X = []\n",
    "validation_data_X = []\n",
    "test_data_X = []\n",
    "\n",
    "trainval_data_Y = []\n",
    "training_data_Y = []\n",
    "validation_data_Y = []\n",
    "test_data_Y = []\n",
    "\n",
    "for i in range(len(mat_names)):\n",
    "    matfile = h5py.File(mat_names[i], 'r')\n",
    "    \n",
    "    trainval_data_X.append(matfile['image'][sorted(train_val_picked),:EEG_channels,:]) #(238, 22, 1000) x 9\n",
    "    training_data_X.append(matfile['image'][sorted(train_picked),:EEG_channels,:]) #(200, 22, 1000) x 9\n",
    "    validation_data_X.append(matfile['image'][sorted(val_picked),:EEG_channels,:]) #(38, 22, 1000) x 9\n",
    "    test_data_X.append(matfile['image'][sorted(test_picked),:EEG_channels,:]) #(50, 22, 1000) x 9\n",
    "    \n",
    "    trainval_data_Y.append(matfile['type'][0,sorted(train_val_picked)] - type_set[1]) #(238, ) x 9\n",
    "    training_data_Y.append(matfile['type'][0,sorted(train_picked)] - type_set[1]) #(200, ) x 9\n",
    "    validation_data_Y.append(matfile['type'][0,sorted(val_picked)] - type_set[1]) #(38, ) x 9\n",
    "    test_data_Y.append(matfile['type'][0,sorted(test_picked)] - type_set[1]) #(50, ) x 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 22, 1000)\n",
      "(200,)\n"
     ]
    }
   ],
   "source": [
    "training_data_shape = training_data_X[0].shape\n",
    "print(training_data_shape) #(200, 22, 1000) while test data shape is (50, 22, 1000) and validation data is (38, 22,1000)\n",
    "print(training_data_Y[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "\n",
    "def remove_nan_rows_A(A, b):\n",
    "    if (np.isnan(A).any() or np.isnan(b).any()):\n",
    "        mask = ~np.isnan(np.sum(A,axis=(1,2))) & ~np.isnan(b[:])\n",
    "        A = A[mask, :, :]\n",
    "        b = b[mask]\n",
    "        \n",
    "    assert A.shape[0] == b.shape[0]\n",
    "    return A, b\n",
    "\n",
    "\n",
    "cnn_trainval_data_X = reduce((lambda x, y: np.concatenate((x, y), axis=0)), trainval_data_X) #(2142, 22, 1000) \n",
    "cnn_training_data_X = reduce((lambda x, y: np.concatenate((x, y), axis=0)), training_data_X) #(1800, 22, 1000)\n",
    "cnn_validation_data_X = reduce((lambda x, y: np.concatenate((x, y), axis=0)), validation_data_X) #(342, 22, 1000)\n",
    "cnn_test_data_X = reduce((lambda x, y: np.concatenate((x, y), axis=0)), test_data_X) #(450, 22, 1000)\n",
    "\n",
    "cnn_trainval_data_Y = reduce((lambda x, y: np.concatenate((x, y), axis=0)), trainval_data_Y) #(2142, )\n",
    "cnn_training_data_Y = reduce((lambda x, y: np.concatenate((x, y), axis=0)), training_data_Y) #(1800, )\n",
    "cnn_validation_data_Y = reduce((lambda x, y: np.concatenate((x, y), axis=0)), validation_data_Y) #(342, )\n",
    "cnn_test_data_Y = reduce((lambda x, y: np.concatenate((x, y), axis=0)), test_data_Y) #(450,)\n",
    "\n",
    "cnn_trainval_data_X, cnn_trainval_data_Y = remove_nan_rows_A(cnn_trainval_data_X, cnn_trainval_data_Y) #(1775,22,1000)\n",
    "cnn_training_data_X, cnn_training_data_Y = remove_nan_rows_A(cnn_training_data_X, cnn_training_data_Y) #(1775,22,1000)\n",
    "cnn_validation_data_X, cnn_validation_data_Y = remove_nan_rows_A(cnn_validation_data_X, cnn_validation_data_Y) #(340,22,1000)\n",
    "cnn_test_data_X, cnn_test_data_Y = remove_nan_rows_A(cnn_test_data_X, cnn_test_data_Y) #(443,22,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1774, 22, 1000)\n",
      "(339, 22, 1000)\n",
      "(445, 22, 1000)\n",
      "(1774, 1000, 22)\n",
      "(339, 1000, 22)\n",
      "(445, 1000, 22)\n"
     ]
    }
   ],
   "source": [
    "print(cnn_training_data_X.shape)\n",
    "print(cnn_validation_data_X.shape)\n",
    "print(cnn_test_data_X.shape)\n",
    "\n",
    "cnn_trainval_data_X = np.transpose(cnn_trainval_data_X, (0,2,1))\n",
    "cnn_training_data_X = np.transpose(cnn_training_data_X, (0,2,1))\n",
    "cnn_validation_data_X = np.transpose(cnn_validation_data_X, (0,2,1))\n",
    "cnn_test_data_X = np.transpose(cnn_test_data_X, (0,2,1))\n",
    "\n",
    "mean_list = np.mean(cnn_trainval_data_X.reshape(-1, cnn_trainval_data_X.shape[-1]), axis=0)\n",
    "std_list = np.sqrt((np.var(cnn_trainval_data_X.reshape(-1, cnn_trainval_data_X.shape[-1]), axis=0)))\n",
    "\n",
    "cnn_trainval_data_X = (cnn_trainval_data_X - mean_list)/std_list\n",
    "cnn_training_data_X = (cnn_training_data_X - mean_list)/std_list\n",
    "cnn_validation_data_X = (cnn_validation_data_X - mean_list)/std_list\n",
    "cnn_test_data_X = (cnn_test_data_X - mean_list)/std_list\n",
    "\n",
    "#cnn_trainval_data_X = np.transpose(cnn_trainval_data_X, (0,2,1))\n",
    "#cnn_training_data_X = np.transpose(cnn_training_data_X, (0,2,1))\n",
    "#cnn_validation_data_X = np.transpose(cnn_validation_data_X, (0,2,1))\n",
    "#cnn_test_data_X = np.transpose(cnn_test_data_X, (0,2,1))\n",
    "\n",
    "print(cnn_training_data_X.shape)\n",
    "print(cnn_validation_data_X.shape)\n",
    "print(cnn_test_data_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "from keras import activations\n",
    "from keras import utils\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the squashing function.\n",
    "# we use 0.5 in stead of 1 in hinton's paper.\n",
    "# if 1, the norm of vector will be zoomed out.\n",
    "# if 0.5, the norm will be zoomed in while original norm is less than 0.5\n",
    "# and be zoomed out while original norm is greater than 0.5.\n",
    "def squash(x, axis=-1):\n",
    "    s_squared_norm = K.sum(K.square(x), axis, keepdims=True) + K.epsilon()\n",
    "    scale = K.sqrt(s_squared_norm) / (0.5 + s_squared_norm)\n",
    "    return scale * x\n",
    "\n",
    "\n",
    "# define our own softmax function instead of K.softmax\n",
    "# because K.softmax can not specify axis.\n",
    "def softmax(x, axis=-1):\n",
    "    ex = K.exp(x - K.max(x, axis=axis, keepdims=True))\n",
    "    return ex / K.sum(ex, axis=axis, keepdims=True)\n",
    "\n",
    "\n",
    "# define the margin loss like hinge loss\n",
    "def margin_loss(y_true, y_pred):\n",
    "    lamb, margin = 0.5, 0.1\n",
    "    return K.sum(y_true * K.square(K.relu(1 - margin - y_pred)) + lamb * (\n",
    "        1 - y_true) * K.square(K.relu(y_pred - margin)), axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(y_):\n",
    "    # Function to encode output labels from number indexes \n",
    "    # e.g.: [[5], [0], [3]] --> [[0, 0, 0, 0, 0, 1], [1, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0]]\n",
    "    \n",
    "    y_ = y_.reshape(len(y_))\n",
    "    n_values = int(np.max(y_)) + 1\n",
    "    return np.eye(n_values)[np.array(y_, dtype=np.int32)]  # Returns FLOATS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_classes = 4\n",
    "epochs = 50\n",
    "(x_train, y_train), (x_test, y_test) = (cnn_training_data_X, cnn_training_data_Y), (cnn_validation_data_X, cnn_validation_data_Y)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "# x_train /= 255\n",
    "# x_test /= 255\n",
    "y_train = utils.to_categorical(y_train, num_classes)\n",
    "y_test = utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 1000, 128)         19840     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 500, 32)           20512     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 500, 32)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 250, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 250, 8)            776       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 250, 8)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 125, 8)            0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 4004      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 45,132\n",
      "Trainable params: 45,132\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# A common Conv2D model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv1D(128, 7, padding = 'same',input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('elu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "model.add(Conv1D(32, 5,padding = 'same'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "model.add(Conv1D(8, 3,padding = 'same'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "model.add(Flatten())\n",
    "#model.add(Dense(5000))\n",
    "#model.add(Activation('relu'))\n",
    "\n",
    "#model.add(Dense(1000))\n",
    "#model.add(Activation('relu'))\n",
    "\n",
    "#model.add(Dense(100))\n",
    "#model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate RMSprop optimizer\n",
    "opt = keras.optimizers.Adam(lr=3e-4)\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1774 samples, validate on 339 samples\n",
      "Epoch 1/50\n",
      "1774/1774 [==============================] - 20s 11ms/step - loss: 1.5974 - acc: 0.2452 - val_loss: 1.4759 - val_acc: 0.2507\n",
      "Epoch 2/50\n",
      "1774/1774 [==============================] - 17s 10ms/step - loss: 1.3974 - acc: 0.3027 - val_loss: 1.3977 - val_acc: 0.2979\n",
      "Epoch 3/50\n",
      "1774/1774 [==============================] - 16s 9ms/step - loss: 1.3391 - acc: 0.3467 - val_loss: 1.4060 - val_acc: 0.3156\n",
      "Epoch 4/50\n",
      "1774/1774 [==============================] - 17s 9ms/step - loss: 1.2951 - acc: 0.3935 - val_loss: 1.3726 - val_acc: 0.3333\n",
      "Epoch 5/50\n",
      "1774/1774 [==============================] - 17s 10ms/step - loss: 1.2513 - acc: 0.4397 - val_loss: 1.3703 - val_acc: 0.3569\n",
      "Epoch 6/50\n",
      "1774/1774 [==============================] - 15s 9ms/step - loss: 1.2119 - acc: 0.4735 - val_loss: 1.3656 - val_acc: 0.3599\n",
      "Epoch 7/50\n",
      "1774/1774 [==============================] - 16s 9ms/step - loss: 1.1679 - acc: 0.5085 - val_loss: 1.3459 - val_acc: 0.3687\n",
      "Epoch 8/50\n",
      "1774/1774 [==============================] - 20s 11ms/step - loss: 1.1255 - acc: 0.5355 - val_loss: 1.3389 - val_acc: 0.3776\n",
      "Epoch 9/50\n",
      "1774/1774 [==============================] - 22s 13ms/step - loss: 1.0837 - acc: 0.5428 - val_loss: 1.3227 - val_acc: 0.3953\n",
      "Epoch 10/50\n",
      "1774/1774 [==============================] - 16s 9ms/step - loss: 1.0389 - acc: 0.5812 - val_loss: 1.3014 - val_acc: 0.4130\n",
      "Epoch 11/50\n",
      "1774/1774 [==============================] - 16s 9ms/step - loss: 0.9861 - acc: 0.6218 - val_loss: 1.2902 - val_acc: 0.4100\n",
      "Epoch 12/50\n",
      "1774/1774 [==============================] - 17s 10ms/step - loss: 0.9445 - acc: 0.6370 - val_loss: 1.2894 - val_acc: 0.4307\n",
      "Epoch 13/50\n",
      "1774/1774 [==============================] - 14s 8ms/step - loss: 0.9106 - acc: 0.6483 - val_loss: 1.2838 - val_acc: 0.4336\n",
      "Epoch 14/50\n",
      "1774/1774 [==============================] - 15s 8ms/step - loss: 0.8707 - acc: 0.6759 - val_loss: 1.2877 - val_acc: 0.4631\n",
      "Epoch 15/50\n",
      "1774/1774 [==============================] - 15s 8ms/step - loss: 0.8385 - acc: 0.6905 - val_loss: 1.2839 - val_acc: 0.4484\n",
      "Epoch 16/50\n",
      "1774/1774 [==============================] - 14s 8ms/step - loss: 0.8049 - acc: 0.7069 - val_loss: 1.2804 - val_acc: 0.4720\n",
      "Epoch 17/50\n",
      "1774/1774 [==============================] - 15s 8ms/step - loss: 0.7812 - acc: 0.7125 - val_loss: 1.2997 - val_acc: 0.4690\n",
      "Epoch 18/50\n",
      "1774/1774 [==============================] - 14s 8ms/step - loss: 0.7526 - acc: 0.7176 - val_loss: 1.2944 - val_acc: 0.4720\n",
      "Epoch 19/50\n",
      "1774/1774 [==============================] - 14s 8ms/step - loss: 0.7177 - acc: 0.7407 - val_loss: 1.2803 - val_acc: 0.4720\n",
      "Epoch 20/50\n",
      "1774/1774 [==============================] - 14s 8ms/step - loss: 0.6851 - acc: 0.7610 - val_loss: 1.2925 - val_acc: 0.4867\n",
      "Epoch 21/50\n",
      "1774/1774 [==============================] - 14s 8ms/step - loss: 0.6683 - acc: 0.7689 - val_loss: 1.3103 - val_acc: 0.4690\n",
      "Epoch 22/50\n",
      "1774/1774 [==============================] - 14s 8ms/step - loss: 0.6408 - acc: 0.7740 - val_loss: 1.2951 - val_acc: 0.4661\n",
      "Epoch 23/50\n",
      "1774/1774 [==============================] - 16s 9ms/step - loss: 0.6225 - acc: 0.7880 - val_loss: 1.3132 - val_acc: 0.4779\n",
      "Epoch 24/50\n",
      "1774/1774 [==============================] - 17s 9ms/step - loss: 0.5959 - acc: 0.8005 - val_loss: 1.3020 - val_acc: 0.4661\n",
      "Epoch 25/50\n",
      "1774/1774 [==============================] - 17s 10ms/step - loss: 0.5723 - acc: 0.8140 - val_loss: 1.3283 - val_acc: 0.4867\n",
      "Epoch 26/50\n",
      "1774/1774 [==============================] - 16s 9ms/step - loss: 0.5538 - acc: 0.8179 - val_loss: 1.3208 - val_acc: 0.4720\n",
      "Epoch 27/50\n",
      "1774/1774 [==============================] - 15s 8ms/step - loss: 0.5301 - acc: 0.8281 - val_loss: 1.3427 - val_acc: 0.4897\n",
      "Epoch 28/50\n",
      "1774/1774 [==============================] - 15s 9ms/step - loss: 0.5115 - acc: 0.8331 - val_loss: 1.3493 - val_acc: 0.4749\n",
      "Epoch 29/50\n",
      "1774/1774 [==============================] - 16s 9ms/step - loss: 0.4907 - acc: 0.8472 - val_loss: 1.3588 - val_acc: 0.4779\n",
      "Epoch 30/50\n",
      "1774/1774 [==============================] - 16s 9ms/step - loss: 0.4801 - acc: 0.8506 - val_loss: 1.3667 - val_acc: 0.4867\n",
      "Epoch 31/50\n",
      "1774/1774 [==============================] - 16s 9ms/step - loss: 0.4616 - acc: 0.8574 - val_loss: 1.3924 - val_acc: 0.4779\n",
      "Epoch 32/50\n",
      "1774/1774 [==============================] - 16s 9ms/step - loss: 0.4441 - acc: 0.8625 - val_loss: 1.3764 - val_acc: 0.4749\n",
      "Epoch 33/50\n",
      "1774/1774 [==============================] - 16s 9ms/step - loss: 0.4261 - acc: 0.8698 - val_loss: 1.4186 - val_acc: 0.4749\n",
      "Epoch 34/50\n",
      "1774/1774 [==============================] - 16s 9ms/step - loss: 0.4068 - acc: 0.8805 - val_loss: 1.4262 - val_acc: 0.4867\n",
      "Epoch 35/50\n",
      "1774/1774 [==============================] - 16s 9ms/step - loss: 0.3878 - acc: 0.8828 - val_loss: 1.4369 - val_acc: 0.4985\n",
      "Epoch 36/50\n",
      "1774/1774 [==============================] - 16s 9ms/step - loss: 0.3757 - acc: 0.8906 - val_loss: 1.4384 - val_acc: 0.4838\n",
      "Epoch 37/50\n",
      "1774/1774 [==============================] - 16s 9ms/step - loss: 0.3687 - acc: 0.8952 - val_loss: 1.4489 - val_acc: 0.4808\n",
      "Epoch 38/50\n",
      "1774/1774 [==============================] - 16s 9ms/step - loss: 0.3504 - acc: 0.8997 - val_loss: 1.4740 - val_acc: 0.4690\n",
      "Epoch 39/50\n",
      "1774/1774 [==============================] - 15s 8ms/step - loss: 0.3305 - acc: 0.9126 - val_loss: 1.4724 - val_acc: 0.4779\n",
      "Epoch 40/50\n",
      "1774/1774 [==============================] - 16s 9ms/step - loss: 0.3254 - acc: 0.9126 - val_loss: 1.5011 - val_acc: 0.4779\n",
      "Epoch 41/50\n",
      "1774/1774 [==============================] - 16s 9ms/step - loss: 0.3098 - acc: 0.9143 - val_loss: 1.5485 - val_acc: 0.4956\n",
      "Epoch 42/50\n",
      "1774/1774 [==============================] - 15s 8ms/step - loss: 0.2898 - acc: 0.9262 - val_loss: 1.5431 - val_acc: 0.4690\n",
      "Epoch 43/50\n",
      "1774/1774 [==============================] - 16s 9ms/step - loss: 0.2855 - acc: 0.9295 - val_loss: 1.6263 - val_acc: 0.4720\n",
      "Epoch 44/50\n",
      "1774/1774 [==============================] - 15s 9ms/step - loss: 0.2714 - acc: 0.9301 - val_loss: 1.5685 - val_acc: 0.4985\n",
      "Epoch 45/50\n",
      "1774/1774 [==============================] - 16s 9ms/step - loss: 0.2652 - acc: 0.9346 - val_loss: 1.6060 - val_acc: 0.4838\n",
      "Epoch 46/50\n",
      "1774/1774 [==============================] - 16s 9ms/step - loss: 0.2547 - acc: 0.9391 - val_loss: 1.6212 - val_acc: 0.4985\n",
      "Epoch 47/50\n",
      "1774/1774 [==============================] - 16s 9ms/step - loss: 0.2381 - acc: 0.9476 - val_loss: 1.6220 - val_acc: 0.4897\n",
      "Epoch 48/50\n",
      "1774/1774 [==============================] - 15s 8ms/step - loss: 0.2282 - acc: 0.9476 - val_loss: 1.6379 - val_acc: 0.4838\n",
      "Epoch 49/50\n",
      "1774/1774 [==============================] - 14s 8ms/step - loss: 0.2204 - acc: 0.9543 - val_loss: 1.6850 - val_acc: 0.5044\n",
      "Epoch 50/50\n",
      "1774/1774 [==============================] - 14s 8ms/step - loss: 0.2067 - acc: 0.9628 - val_loss: 1.7059 - val_acc: 0.4985\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17e96cf90>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.539325842697\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(cnn_test_data_X)\n",
    "# round predictions\n",
    "rounded = [np.argmax(x) for x in predictions]\n",
    "print(1.0*np.sum(rounded==cnn_test_data_Y)/len(cnn_test_data_Y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
